{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9327b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98dc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "source_directory = \"source_files/\"\n",
    "output_directory = \"extracted_tables/\"\n",
    "table_code_directory = output_directory + \"table_code/\"\n",
    "table_header_directory = output_directory + \"table_header/\"\n",
    "result_file = \"tables_regex.csv\"\n",
    "\n",
    "if os.path.isdir(output_directory) == False:\n",
    "    os.mkdir(output_directory)\n",
    "\n",
    "if os.path.isdir(table_code_directory) == False:\n",
    "    os.mkdir(table_code_directory)\n",
    "    \n",
    "if os.path.isdir(table_header_directory) == False:\n",
    "    os.mkdir(table_header_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9e88978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2001.00116v2\n",
      "['sample-sigconf.tex', 'table_1.tex', 'table_2.tex', 'table_3.tex', 'table_5.tex', 'table_6.tex', 'table_7.tex']\n",
      "Found caption: Clusters splitting result.}\n",
      "Found caption: Performance of \\oursys. After \\oursys is trained using training datasets that contain benign samples, CW and DeepFool AEs, \\fedit{the detection rate and FPR (the rate of benign samples misclassified as AEs) are measured using testing sets.}}\n",
      "Found caption: Comparison with other AE detectors (DR: Detection Rate). We use the same attack settings as used in prior work~\\cite{ma2019nic,xu2017feature}.}\n",
      "Found caption: Target-model agnostic property of \\oursys.}\n",
      "Found caption: Performance of integrating \\oursys with an existing  detector~\\cite{zuo2019l0}.}\n",
      "Found caption: Impacts of different values of $n$ (CIFAR-10).}\n",
      "Found caption: Impacts of different values of $n$ (ImageNet).}\n",
      "Found caption: Impacts of different values of $n$.}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Save paper name and authors as metadata\n",
    "output_file_path = output_directory + result_file\n",
    "with open(output_file_path, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    for paper in os.listdir(source_directory):\n",
    "        path = source_directory + paper\n",
    "        if os.path.isdir(path):\n",
    "            print(\"\\n\\n\" + paper)\n",
    "            tex_files = [x for x in os.listdir(path) if x.endswith('.tex')]\n",
    "            print(tex_files)\n",
    "\n",
    "            complete_tex = \"\"\n",
    "            for file in tex_files:\n",
    "                try:\n",
    "                    f = open(path + \"/\" + file, \"r\", encoding=\"utf8\")\n",
    "                    complete_tex += f.read()\n",
    "                    f.close()\n",
    "                except UnicodeDecodeError as e:\n",
    "                    print(\"UnicodeDecodeError occurred. File could not be loaded.\")\n",
    "                    continue\n",
    "            #print(\"Complete tex source:\\n\" + complete_tex)\n",
    "\n",
    "            '''\n",
    "            Different LATEX tables:\n",
    "                -table\n",
    "                -table*\n",
    "                -tabular\n",
    "                -tabularx\n",
    "            '''\n",
    "            found_title = re.search(r\"\\\\title\\{(.*)\\}\", complete_tex)\n",
    "            found_document_header = re.search(r\"\\\\documentclass\\[.*\\\\begin\\{document\\}\", complete_tex, re.DOTALL)\n",
    "            paper_id = str(uuid.uuid4())\n",
    "            if found_document_header and found_title:\n",
    "                #print(found_title.group(1))\n",
    "                #print(found_document_header.group(0))\n",
    "                \n",
    "                paper_header_file = table_header_directory + paper_id + \".txt\"\n",
    "                f = open(paper_header_file, \"w\")\n",
    "                f.write(found_document_header.group(0))\n",
    "                f.close()\n",
    "            found_tables = re.findall(r\"\\\\begin\\{table\\*?\\}.*?\\\\end\\{table\\*?\\}\", complete_tex, re.DOTALL)\n",
    "            for table in found_tables:\n",
    "                #r\"\\\\caption\\{(.*?)}\"\n",
    "                caption_match = re.search(r\"\\\\caption\\{(.*)}\", table)\n",
    "                if caption_match:\n",
    "                    found_caption = caption_match.group(1)\n",
    "                    original_caption = found_caption\n",
    "                    full_label_match = re.search(r\"\\\\label\\{.*?\\}\", found_caption)\n",
    "                    half_label_match = re.search(r\"\\\\label\\{.*\", found_caption)\n",
    "                    if full_label_match:\n",
    "                        found_caption = found_caption.replace(full_label_match.group(0), \"\")\n",
    "                        #print(\"Found full label: \" + full_label_match.group(0))\n",
    "                    elif half_label_match:\n",
    "                        found_caption = found_caption.replace(half_label_match.group(0), \"\")\n",
    "                        #print(\"Found half label: \" + half_label_match.group(0))\n",
    "                    print(\"Found caption: \" + found_caption)\n",
    "                    table_id = str(uuid.uuid4())\n",
    "                    \n",
    "                    spamwriter.writerow([table_id, paper_id, found_caption, original_caption])\n",
    "                    table_file_path = table_code_directory + table_id + \".txt\"\n",
    "                    f = open(table_file_path, \"w\")\n",
    "                    f.write(table)\n",
    "                    f.close()\n",
    "                    \n",
    "                #print(\"Found table: \\n\" + table + \"\\n\\n\")\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53cb565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
