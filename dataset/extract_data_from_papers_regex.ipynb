{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import uuid\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98dc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "source_dir = \"source_files/\"\n",
    "\n",
    "table_output_dir = \"extracted_tables/\"\n",
    "table_code_dir = table_output_dir + \"table_code/\"\n",
    "table_header_dir = table_output_dir + \"table_header/\"\n",
    "table_result_file = \"tables_regex.csv\"\n",
    "\n",
    "figure_output_dir = \"extracted_figures/\"\n",
    "figure_result_file = \"figures_regex.csv\"\n",
    "\n",
    "possible_extensions = [\".pdf\", \".png\", \".jpg\", \".jpeg\", \".eps\"]\n",
    "\n",
    "os.makedirs(table_output_dir, exist_ok=True)\n",
    "os.makedirs(table_header_dir, exist_ok=True)\n",
    "os.makedirs(table_code_dir, exist_ok=True)\n",
    "os.makedirs(figure_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset directories\n",
    "files = glob.glob(table_code_dir + \"*\")\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "    \n",
    "files = glob.glob(table_header_dir + \"*\")\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "    \n",
    "files = glob.glob(figure_output_dir + \"*\")\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "if os.path.isfile(table_output_dir + table_result_file):\n",
    "    os.remove(table_output_dir + table_result_file)\n",
    "    \n",
    "if os.path.isfile(figure_output_dir + figure_result_file):\n",
    "    os.remove(figure_output_dir + figure_result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e88978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save paper name and authors as metadata\n",
    "csvfile_table = open(table_output_dir + table_result_file, 'w', newline='', encoding=\"utf-8\")\n",
    "spamwriter_table = csv.writer(csvfile_table, delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "csvfile_figure = open(figure_output_dir + figure_result_file, 'w', newline='', encoding=\"utf-8\")\n",
    "spamwriter_figure = csv.writer(csvfile_figure, delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "for paper in os.listdir(source_dir):\n",
    "    paper_path = source_dir + paper\n",
    "    if os.path.isdir(paper_path):\n",
    "        print(\"\\n\\n\" + paper)\n",
    "        tex_files = [x for x in os.listdir(paper_path) if x.endswith('.tex')]\n",
    "\n",
    "        complete_tex = \"\"\n",
    "        for file in tex_files:\n",
    "            try:\n",
    "                f = open(paper_path + \"/\" + file, \"r\", encoding=\"utf8\")\n",
    "                complete_tex += f.read()\n",
    "                f.close()\n",
    "            except UnicodeDecodeError as e:\n",
    "                print(\"UnicodeDecodeError occurred. File could not be loaded.\")\n",
    "                continue\n",
    "\n",
    "        found_document_header = re.search(r\"\\\\documentclass\\[.*\\\\begin\\{document\\}\", complete_tex, re.DOTALL)\n",
    "        paper_id = str(uuid.uuid4())\n",
    "        if found_document_header:\n",
    "            paper_header_file = table_header_dir + paper_id + \".txt\"\n",
    "            f = open(paper_header_file, \"w\", encoding=\"utf-8\")\n",
    "            f.write(found_document_header.group(0))\n",
    "            f.close()\n",
    "        else:\n",
    "            print(\"Document header could not be identified.\")\n",
    "            continue\n",
    "\n",
    "        found_tables = re.findall(r\"\\\\begin\\{table\\*?\\}.*?\\\\end\\{table\\*?\\}\", complete_tex, re.DOTALL)\n",
    "        found_figures = re.findall(r\"\\\\begin\\{figure\\*?\\}.*?\\\\end\\{figure\\*?\\}\", complete_tex, re.DOTALL)\n",
    "\n",
    "        for table in found_tables:\n",
    "            #r\"\\\\caption\\{(.*?)}\"\n",
    "            caption_match = re.search(r\"\\\\caption\\{(([^{}]*(\\{[^{}]*\\})?[^{}]*)+)\\}\", table)\n",
    "            if caption_match:\n",
    "                found_caption = caption_match.group(1)\n",
    "                table_id = str(uuid.uuid4())\n",
    "\n",
    "                spamwriter_table.writerow([table_id, paper_id, found_caption])\n",
    "                table_file_path = table_code_dir + table_id + \".txt\"\n",
    "                f = open(table_file_path, \"w\", encoding=\"utf-8\")\n",
    "                f.write(table)\n",
    "                f.close()\n",
    "\n",
    "        for figure in found_figures:\n",
    "            found_graphics = re.findall(r\"\\\\includegraphics(\\[.*?\\])*\\{(.*?)\\}\", figure)\n",
    "            caption_match = re.search(r\"\\\\caption\\{(([^{}]*(\\{[^{}]*\\})?[^{}]*)+)\\}\", table)\n",
    "            if caption_match:\n",
    "                found_caption = caption_match.group(1)\n",
    "                for graphic in found_graphics:\n",
    "                    figure_id = str(uuid.uuid4())\n",
    "                    \n",
    "                    graphic_path = graphic[1]\n",
    "                    file_type = os.path.splitext(graphic_path)[-1]\n",
    "                    if os.path.isfile(paper_path+\"/\"+graphic_path):\n",
    "                        graphic_path = paper_path+\"/\"+graphic_path\n",
    "                    else:\n",
    "                        for ext in possible_extensions:\n",
    "                            possible_path = paper_path+\"/\"+graphic_path + ext\n",
    "                            if os.path.isfile(possible_path):\n",
    "                                graphic_path = possible_path\n",
    "                                break\n",
    "                                \n",
    "                    try:\n",
    "                        shutil.copy(graphic_path, figure_output_dir+figure_id+file_type)\n",
    "                        spamwriter_figure.writerow([figure_id, paper_id, found_caption])\n",
    "                    except FileNotFoundError as e:\n",
    "                        print(f\"File not found: {graphic_path} - {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "        print(f\"{len(found_tables)} tables found.\")\n",
    "        print(f\"{len(found_figures)} figures found.\")\n",
    "    #break\n",
    "    \n",
    "csvfile_table.close()\n",
    "csvfile_figure.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile_table.close()\n",
    "csvfile_figure.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53cb565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
