{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefb9f3-2e49-4ddb-a85e-4a2988cb24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b05f38-0713-4fae-9728-50db442c78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables and directories\n",
    "qa_output_dir = \"qa_output/\"\n",
    "\n",
    "table_dir = \"extracted_tables/\"\n",
    "table_image_dir = table_dir + \"table_images/\"\n",
    "table_code_dir = table_dir + \"table_code/\"\n",
    "table_metadata = table_dir + \"tables.csv\"\n",
    "\n",
    "figure_dir = \"extracted_figures/\"\n",
    "figure_metadata = figure_dir + \"figures.csv\"\n",
    "\n",
    "os.makedirs(qa_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735f261-dad5-4cbe-b0e7-5026592e4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define QA-Pair-Generation Prompts\n",
    "table_prompt = \"Generate an open-ended question and its corresponding answer based on a scientific table. Use its caption and text mentions \\\n",
    "from the scientific paper to create a question that tests the understanding of this specific table. Also, include a difficulty level, either \\\n",
    "“easy” or \\ “hard”, where easy indicates that little reasoning is required, and hard indicates that complex reasoning is required to answer the \\\n",
    "question. \\\n",
    "Table: {table_code} \\\n",
    "Caption: {caption} \\\n",
    "Text mentions: {text_mentions} \\\n",
    "Question: \\\n",
    "Answer: \\\n",
    "Difficulty: \"\n",
    "\n",
    "figure_prompt = \"Generate an open-ended question and its corresponding answer based on a scientific figure. Use its caption and text mentions \\\n",
    "from the scientific paper to create a question that tests the understanding of this specific figure. Also, include a difficulty level, either \\\n",
    "“easy” or \\ “hard”, where easy indicates that little reasoning is required, and hard indicates that complex reasoning is required to answer the \\\n",
    "question. \\\n",
    "Caption: {caption} \\\n",
    "Text mentions: {text_mentions} \\\n",
    "Question: \\\n",
    "Answer: \\\n",
    "Difficulty: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd0f8c-558b-4a2f-93c5-f53fafbe9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-VL-Chat\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat\", device_map=\"cuda\", trust_remote_code=True).eval()\n",
    "\n",
    "query = tokenizer.from_list_format([\n",
    "    {'image': 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'},\n",
    "    {'text': 'Explain me this picture'},\n",
    "])\n",
    "response, history = model.chat(tokenizer, query=query, history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354da044-b23f-4f26-9c74-fabef050056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a qa_pair, either for a figure or a table\n",
    "def generate_qa_pair(object_id, image_file, caption, text_mentions, table_code=None):\n",
    "    # Modifying the prompt\n",
    "    prompt = None\n",
    "    if table_code:\n",
    "        prompt = table_prompt.replace(\"{caption}\", caption).replace(\"{text_mentions}\", text_mentions).replace(\"{table_code}\", table_code)\n",
    "    else:\n",
    "        prompt = figure_prompt.replace(\"{caption}\", caption).replace(\"{text_mentions}\", text_mentions)\n",
    "\n",
    "    # Executing the query\n",
    "    query = tokenizer.from_list_format([\n",
    "        {'image': 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg'},\n",
    "        {'text': 'Explain me this picture'},\n",
    "    ])\n",
    "\n",
    "    # Receiving the results and store them in file\n",
    "    response, history = model.chat(tokenizer, query=query, history=None)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3b258-75de-4bd5-9c12-543d412d14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read either figure or table data from csv file\n",
    "def get_object_data(meta_file, start_index, end_index, table=False):\n",
    "    object_data = {}\n",
    "    with open(meta_file, \"r\", newline='', encoding='utf-8') as csv_file:\n",
    "        spamreader = csv.reader(input_file, delimiter=';', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        index = 0\n",
    "        for row in spamreader:\n",
    "            if index >= start_index:\n",
    "                object_id = row[0]\n",
    "                caption = row[4]\n",
    "                text_mentions = row[5]\n",
    "\n",
    "                if table: # For tables\n",
    "                    try:\n",
    "                        table_code = get_table_code(table_code_dir + figure_id + \".tex\")\n",
    "                        object_data[object_id] = (caption, text_mentions, table_code)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error occurred for index {index}: {e}\")\n",
    "                else: # For figures\n",
    "                    object_data[object_id] = (caption, text_mentions)\n",
    "            index += 1\n",
    "            if index > end_index:\n",
    "                break\n",
    "\n",
    "    return object_data\n",
    "\n",
    "# Return table code\n",
    "def get_table_code(code_file):\n",
    "    table_code = None\n",
    "    if os.path.isfile(code_path):\n",
    "        with open(code_path, \"r\", encoding='utf-8') as code_file:\n",
    "            table_code = code_file.read()\n",
    "            splitted_code = table_code.split(\"\\pagenumbering{gobble}\")\n",
    "            if len(splitted_code) != 2:\n",
    "                raise ValueError(f\"Unexpected occurrence of pagenumbering. Please check manually {code_file}\")\n",
    "            table_code = splitted_code[-1]\n",
    "            table_code = table_code.replace(\"\\end{document}\", \"\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{code_file} was not found.\")\n",
    "    return table_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcf78e-63c9-4c3b-8ce4-3dd4a9574646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute whole QA generation for either figures or tables, following a range of indexes in the metadata file\n",
    "def execute_generation(start_index, end_index, table=False):\n",
    "    print(\"Data extraction from csv file started.\")\n",
    "    object_data = None\n",
    "    if table:\n",
    "        object_data = get_object_data(table_metadata, start_index, end_index, True)\n",
    "    else:\n",
    "        object_data = get_object_data(figure_metadata, start_index, end_index)\n",
    "\n",
    "    print(\"QA-pair generation started.\")\n",
    "    counter = 0\n",
    "    for obj in object_data:\n",
    "        image_file = None\n",
    "        table_code = None\n",
    "        caption = object_data[obj][0]\n",
    "        text_mentions = object_data[obj][1]\n",
    "        if table:\n",
    "            image_file = table_image_dir + obj + \".png\"\n",
    "            table_code = object_data[obj][2]\n",
    "        else:\n",
    "            image_file = figure_image_dir + obj + \".png\"\n",
    "            \n",
    "        response = generate_qa_pair(obj, image_file, caption, text_mentions, table_code)\n",
    "        output_file = qa_output_dir + obj + \".txt\n",
    "        with open(output_file, \"w\", encoding='utf-8') as output:\n",
    "            output.write(response)\n",
    "\n",
    "        counter += 1\n",
    "        if counter % int(len(counter)/10) == 0:\n",
    "            print(\"{counter} objects have been processed.\")\n",
    "\n",
    "    print(\"Process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01905128-6507-4e30-b3e2-8f0180a9e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model and function parameters\n",
    "model_id = \"Qwen/Qwen-VL-Chat\"\n",
    "s_index = 0\n",
    "e_index = 15\n",
    "is_table = True\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", trust_remote_code=True).eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "# Execute QA generation\n",
    "execute_generation(s_index, e_index, is_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
