{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3dc16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'TexSoup'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\fabia\\desktop\\uni\\masterthesis\\masterthesis_code\\dataset\\texsoup\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: TexSoup\n",
      "  Building wheel for TexSoup (setup.py): started\n",
      "  Building wheel for TexSoup (setup.py): finished with status 'done'\n",
      "  Created wheel for TexSoup: filename=TexSoup-0.3.1-py3-none-any.whl size=27928 sha256=14c885e753cd326507f403281af49c7f4f77e1bbcc78b1580035ffd086a5d262\n",
      "  Stored in directory: C:\\Users\\fabia\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-fzx_4vc3\\wheels\\88\\57\\0d\\c42c5ff2ec605fd440078a50bd506a72a97124eec08190add7\n",
      "Successfully built TexSoup\n",
      "Installing collected packages: TexSoup\n",
      "  Attempting uninstall: TexSoup\n",
      "    Found existing installation: TexSoup 0.3.1\n",
      "    Uninstalling TexSoup-0.3.1:\n",
      "      Successfully uninstalled TexSoup-0.3.1\n",
      "Successfully installed TexSoup-0.3.1\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/alvinwan/TexSoup.git\n",
    "!git clone -b gh-pages https://github.com/alvinwan/TexSoup.git\n",
    "import os\n",
    "original_dir = os.getcwd()\n",
    "os.chdir('TexSoup')\n",
    "!pip install .\n",
    "os.chdir(original_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68bff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from TexSoup import TexSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1a9aa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2001.00116v2\n",
      "['sample-sigconf.tex', 'table_1.tex', 'table_2.tex', 'table_3.tex', 'table_5.tex', 'table_6.tex', 'table_7.tex']\n",
      "Clusters splitting result.\n",
      "Performance of \\oursys. After \\oursys is trained using training datasets that contain benign samples, CW and DeepFool AEs, \\fedit{the detection rate and FPR (the rate of benign samples misclassified as AEs) are measured using testing sets.}\n",
      "Comparison with other AE detectors (DR: Detection Rate). We use the same attack settings as used in prior work~\\cite{ma2019nic,xu2017feature}.\n",
      "Target-model agnostic property of \\oursys.\n",
      "Performance of integrating \\oursys with an existing  detector~\\cite{zuo2019l0}.\n",
      "Impacts of different values of $n$(CIFAR-10).\n",
      "Impacts of different values of $n$(ImageNet).\n",
      "Impacts of different values of $n$.\n",
      "Tables amount: 8\n",
      "\n",
      "\n",
      "2001.00117v1\n",
      "['arXiv.tex']\n",
      "Error Type: TypeError\n",
      "Error Message: [Line: 0, Offset 17108] Malformed argument. First and last elements must match a valid argument form\n",
      "\n",
      "\n",
      "2001.00119v2\n",
      "['main.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00120v1\n",
      "['Doubly-symmetric_perioidc_orbits_in_the_spatial_Hill_s_lunar_problem_with_oblate_secondary_primary.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 7216] \"align\" env expecting \\end{align}. Instead got \\end{array}\\\n",
      "\n",
      "\n",
      "2001.00122v1\n",
      "['dpaper_5.tex']\n",
      "Error Type: TypeError\n",
      "Error Message: [Line: 0, Offset 110813] Malformed argument. First and last elements must match a valid argument for\n",
      "\n",
      "\n",
      "2001.00124v1\n",
      "['ZTF-EP-19-06.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00125v1\n",
      "['abstract.tex', 'acktext.tex', 'authorlist.tex', 'mu69occ.tex', 'tblast.tex', 'tblaug04ev.tex', 'tblaug04sta.tex', 'tblerrors.tex', 'tblfixed.tex', 'tbljul17ev.tex', 'tbljul17sta.tex', 'tbljun3sta.tex', 'tblstars.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00126v1\n",
      "['On_two_problems_about_isogenies_of_elliptic_curves_over_finite_fields.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00127v2\n",
      "['start.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 3127] \"$\" env expecting $. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00128v3\n",
      "['main.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 14269] \"aligned\" env expecting \\end{aligned}. Instead got \\end{matrix}\\\n",
      "\n",
      "\n",
      "2001.00131v1\n",
      "['signalNcompr_MASS_JExt.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00132v1\n",
      "['diffusion.tex', 'math_commands.tex', 'supplement.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00133v2\n",
      "['aassymbols.tex', 'main.tex']\n",
      "Additional \\aastex\\symbols\n",
      "Text-mode accents\n",
      "National symbols\n",
      "Math-mode accents\n",
      "Greek and Hebrew letters (math mode)\n",
      "Binary operators (math mode)\n",
      "AMS binary operators (math mode)\n",
      "Miscellaneous symbols\n",
      "Miscellaneous symbols (math mode)\n",
      "AMS miscellaneous symbols (math mode)\n",
      "Arrows (math mode)\n",
      "AMS arrows (math mode)\n",
      "Relations (math mode)\n",
      "AMS binary relations (math mode)\n",
      "AMS negated relations (math mode)\n",
      "Variable-sized symbols (math mode)\n",
      "Delimiters (math mode)\n",
      "Function names (math mode)\n",
      "\\small{Summary of key parameters and results.  HEP is the hydrodynamic escape parameter.  The inner radius is derived from the choice of HEP as $r_0 = \\left(1 - \\Gamma \\right)GM_{\\rm BH}\\text{HEP}^{-1} c_{s,0}^{-2}$ (see Eq.~\\ref{eq:hep}), while the density at the base follows from the definition of $\\xi$ as $\\rho_0 = \\mu m_{p} L_{\\rm X}\\xi_{0}^{-1} r_{0}^{-2}$.  The sound crossing time is defined as $t_{\\rm sc,0} = (r_{\\rm out} - r_{0}) / c_{\\rm s,0}$.  \n",
      "The ratio $t_{\\rm cool} / t_{\\rm sc}$ is given at the location where $\\Xi = \\Xi_{\\rm c,max}$.\n",
      "The average mass flux and velocity through $r_{\\rm{out}}$ are shown as $\\avg{\\dot{M}}$ and $\\avg{v}$.\n",
      "%with the values for the high resolution (8x) runs shown in parenthesis.  Comment columns denote whether the 1x and 8x runs are steady, unsteady, or quasi-steady. \n",
      "Comment columns denote the state of the flow at late times.  Values/comments in parenthesis denote results for the 8x-resolution runs.\n",
      "}\n",
      "Tables amount: 19\n",
      "\n",
      "\n",
      "2001.00134v1\n",
      "['ip.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00136v1\n",
      "['asymmetric.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00137v2\n",
      "['elsarticle-template.tex']\n",
      "Types of mistakes on the Twitter dataset.\n",
      "Examples of original tweets and their corrected version.\n",
      "Details about our Twitter Sentiment Classification dataset, composed of incorrect and correct data.\n",
      "Details about our Incomplete Intent Classification dataset based on the Chatbot NLU Evaluation Corpus.\n",
      "Example of sentence from Chatbot NLU Corpus with different TTS-STT combinations and their respective inverted BLEU and WER scores, which denote the level of noise in the text.\n",
      "F1-micro scores for the Twitter Sentiment Classification task on Kaggle's Sentiment140 Corpus. Note that: (\\textit{Inc}) is the original dataset, with naturally incorrect tweets, (\\textit{Corr}) is the corrected version of the dataset and (\\textit{Inc+Corr}) contains both. The noise level is represented by the iBLEU score.\n",
      "F1-micro scores for the Chatbot Intent Classification Corpus. Note that we include results with the original sentences (complete data) and sentences imbued with TTS-STT error (\\textit{gtts-witai} and \\textit{macsay-witai}), with the noise level being represented by the iBLEU and WER scores.\n",
      "Macro-average precision (P), recall (R), and F1 scores (\\%) for the Twitter Sentiment Classification Corpus. Note that: (\\textit{Inc}) is the original dataset, with naturally incorrect tweets, (\\textit{Corr}) is the corrected version of the dataset and (\\textit{Inc+Corr}) contains both.\n",
      "Macro-average precision (P), recall (R), and F1 scores (\\%) for the Chatbot Intent Classification Corpus with the original sentences (complete data) and sentences imbued with TTS-STT error (\\textit{gtts-witai} and \\textit{macsay-witai}).\n",
      "Comparison of performance improvement in relation to varying levels of noise between the TTS-STT Chatbot datasets, namely \\textit{gtts-witai} and \\textit{macsay-witai}, and the Twitter Sentiment Dataset with incorrect text (\\textit{Inc}). Note that, for fair comparison, the WER score for the Twitter dataset has also been included here, even though that score is usually only used to measure levels of noise in text with STT error, which is only present in the Chatbot corpus.\n",
      "Average number of words per sentence in the TTS-STT Chatbot datasets, namely \\textit{gtts-witai} and \\textit{macsay-witai}, and the Twitter Sentiment Dataset with incorrect text (\\textit{Inc}).\n",
      "Tables amount: 11\n",
      "\n",
      "\n",
      "2001.00138v4\n",
      "['Paper.tex', 'todo-list.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00139v1\n",
      "['OCR_Rizwan.tex']\n",
      "Distribution of databases of selected studies before and after applying selection process\n",
      "Extracted meta-data fields of selected studies\n",
      "Research questions and motivation\n",
      "Tables amount: 3\n",
      "\n",
      "\n",
      "2001.00140v3\n",
      "['main.tex']\n",
      "Error Type: TypeError\n",
      "Error Message: [Line: 0, Offset 77206] Malformed argument. First and last elements must match a valid argument form\n",
      "\n",
      "\n",
      "2001.00141v1\n",
      "['consensus.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00143v3\n",
      "['Ghobadi_Mahmoudzadeh_InferringFeasRegion_2020.tex']\n",
      "Numerical Case I\n",
      "Numerical Case II\n",
      "Numerical Case III: Two objective functions were considered for a set of 100 observations on 26 food items. The set of constraints includes 8 known constraints, the half-space, and 30 unknown constraints.\n",
      "Average distance of recommended diets for each of the two objectives tested with and without the imputed constraints.\n",
      "For every consumed food item, the number of consumption, the average serving size, and the standard deviation is provided in columns Count, Avg. Consumption, and Std. Dev., respectively. \n",
      "Tables amount: 5\n",
      "\n",
      "\n",
      "2001.00145v1\n",
      "['main_aut.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00147v1\n",
      "['FHEP-arXiv.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00148v1\n",
      "['paper.tex']\n",
      "Error Type: AttributeError\n",
      "Error Message: 'NoneType' object has no attribute 'contents'\n",
      "\n",
      "\n",
      "2001.00151v1\n",
      "['PolaritonLZ12.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 970] \"eqnarray\" env expecting \\end{eqnarray}. Instead got \\end{array}\\\n",
      "\n",
      "\n",
      "2001.00152v1\n",
      "['improved_rate.tex', 'tmp_improved_rate_header.tex']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00153v1\n",
      "['two_ecai.tex']\n",
      "Classification accuracy (\\%) on Office-31 for unsupervised domain adaptation with ResNet-50.\n",
      "Classification accuracy (\\%) on ImageCLEF-DA for unsupervised domain adaptation with ResNet-50.\n",
      "Optimal hyperparameters on Office-31 dataset.\n",
      "Cross-domain $A$-distance of different approaches.\n",
      "Tables amount: 4\n",
      "\n",
      "\n",
      "2001.00154v1\n",
      "['stability_HHI_arX.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 3675] \"eqnarray\" env expecting \\end{eqnarray}. Instead got \\end{widetext}\n",
      "We then \n",
      "\n",
      "\n",
      "2001.00160v1\n",
      "['apstemplate.tex']\n",
      "Error Type: TypeError\n",
      "Error Message: [Line: 0, Offset 59345] Malformed argument. First and last elements must match a valid argument form\n",
      "\n",
      "\n",
      "2001.00161v1\n",
      "['BcSpectrum.tex']\n",
      "\\label{tab:parametersBC} Three sets of the parameters $\\omega_f$ and $D_f$(in GeV) of the charm and bottom system \\cite{Chen2019}.\n",
      "\\label{tab:massccbar} Masses (in MeV) of the charmonium with $J^{PC}\\,=\\,0^{-+},\\,1^{--},\\,0^{++},\\,1^{+-},\\,1^{++},\\,2^{++}$, the normal states in the quark model. $M^{\\textmd{RL}}_{c\\bar{c}}$ is our RL approximation result. $M^{\\textmd{expt.}}_{c\\bar{c}}$ is the experiment value \\cite{Tanabashi2018}. $\\Delta M^{\\textmd{RL}}_{c\\bar{c}} = M^{\\textmd{RL}}_{c\\bar{c}} - M^{\\textmd{expt.}}_{c\\bar{c}}$ is the deviation of our results from the experiment value. Three sets of parameters in Tab. \\ref{tab:parametersBC} are used in our calculation. \n",
      "\\label{tab:massbbbar} Masses (in MeV) of the bottomonium. The meanings of the quantities are the same as in Tab. \\ref{tab:massccbar}.\n",
      "\\label{tab:massExcited}\n",
      "The masses (in MeV) of the first radial excited states of the charm-bottom system with $J^{P}=0^{-}$(cited from Ref. \\cite{Chang2019}).\n",
      "The experiment data for $M_{\\eta_{c}(2S)}$ and $M_{\\eta_{b}(2S)}$ are taken from Ref.~\\cite{Tanabashi2018},\n",
      "and that for $M_{B^+_{c}(2S)}$ is taken from Ref.~\\cite{Aaij2019}.\n",
      "\\label{tab:masscbRL} Masses of the $B_c$ Mesons (in MeV). $M^{\\textmd{RL}}_{c\\bar{b}}$ is the direct RL result. $\\Delta M^{\\textmd{RL}}_{c\\bar{b}}$ is the error of the RL approximation defined by Eq.(\\ref{eq:errorMbc}). $\\bar{M}^{\\textmd{RL}}_{c\\bar{b}}$ is the modified mass, defined by Eq.(\\ref{eq:modifiedMass}).\n",
      "\\label{tab:masscball} Masses of the $B_c$ Mesons (in MeV).  $\\bar{M}^{\\textmd{RL}}_{c\\bar{b}}$ is our prediction. The first error is due to the interaction pattern Eq.(\\ref{eq:gluonfmodel}) $\\sim$ Eq.(\\ref{eq:gluonUltraviolet}). The second error is due to the varying of the parameters. For $J^{P} = 1^+$ mesons, the third error is due to the $C-$parity average in Eq.(\\ref{eq:errorMbc}). $M^{\\textmd{QM}}_{c\\bar{b}}$ is the quark model result \\cite{Li2019}, and the underlined ones are the input values. $M^{\\textmd{LQCD}}_{c\\bar{b}}$ is the lQCD prediction \\cite{Mathur2018}. $M^{\\textmd{expt.}}_{c\\bar{b}}$ is the experiment value \\cite{Tanabashi2018}.\n",
      "Tables amount: 6\n",
      "\n",
      "\n",
      "2001.00164v2\n",
      "['archive-AIR.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 1722] \"list\" env expecting \\end{list}. Instead got \\end{document}\n",
      "\n",
      "\n",
      "\n",
      "2001.00166v1\n",
      "['46-100.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 5076] \"comment\" env expecting \\end{comment}. Instead got \\end{proof}\n",
      "\n",
      "\n",
      "\n",
      "2001.00167v1\n",
      "['Vaneeva-revised3.tex']\n",
      "Error Type: AttributeError\n",
      "Error Message: 'NoneType' object has no attribute 'contents'\n",
      "\n",
      "\n",
      "2001.00168v1\n",
      "['Galaxy_radioIR.tex']\n",
      "A compilation of some known properties for the two galaxies: NGC 3184 and NGC 7793 in our sample.\n",
      "A comparative chart showing details of imaging observations using different telescopes/instruments available for the two galaxies. The molecular CO data for NGC 7793 was unavailable, as per our requirements.\n",
      "\\label{corr_irHI}\\normalsize\\textbf{Spearman's ($\\rho$)} and \\textbf{Kendall's ($\\tau$)} rank correlation coefficients among the gas column densities and dust IR intensities for NGC 3184 and NGC 7793.\n",
      "\\label{corr_mfir}\\normalsize\\textbf{Spearman's ($\\rho$}) and \\textbf{Kendall's ($\\tau$)} rank correlation coefficients among the mid-IR and far-IR dust intensities for NGC 3184 and NGC 7793.\n",
      "Tables amount: 4\n",
      "\n",
      "\n",
      "2001.00169v1\n",
      "['LDG.tex']\n",
      "UnicodeDecodeError occurred. File could not be loaded.\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00172v1\n",
      "['new_meson_spectrum.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 1683] \"eqnarray\" env expecting \\end{eqnarray}. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00173v1\n",
      "['Flockingv13.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 11082] \"$\" env expecting $. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00174v1\n",
      "['Resubmit_clean.tex']\n",
      "UnicodeDecodeError occurred. File could not be loaded.\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00175v2\n",
      "['YstateR1.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 13017] \"$\" env expecting $. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00176v2\n",
      "['SK-paper_final_v3.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00177v2\n",
      "['paper.tex']\n",
      "Table of all the six cases for frequencies\n",
      "Tables amount: 1\n",
      "\n",
      "\n",
      "2001.00178v2\n",
      "['iGRM_NavierStokes.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00179v3\n",
      "['manuscript_Vera_v4.tex']\n",
      "\\textbf{Entire Face Synthesis:} Publicly available databases.\n",
      "\\textbf{Entire Face Synthesis:} Comparison of different state-of-the-art detection approaches. The best results achieved for each public database are remarked in \\textbf{bold}. Results in \\textit{italics} indicate that they were not provided in the original work. \\hspace{\\textwidth} AUC = Area Under the Curve, Acc. = Accuracy, EER = Equal Error Rate. \n",
      "\\textbf{Identity Swap:} Publicly available databases.\n",
      "\\textbf{Identity Swap:} Comparison of different state-of-the-art detection approaches. The best results achieved for each public database are remarked in \\textbf{bold}. Results in \\textit{italics} indicate that they were published in~\\cite{li2019celebdf}, but not in the original work. FF++ = FaceForensics++, AUC = Area Under the Curve, Acc. = Accuracy, EER = Equal Error Rate, TCR = True Classification Rates.\n",
      "\\textbf{Attribute Manipulation:} Comparison of different state-of-the-art detection approaches. The best results achieved for each public database are remarked in \\textbf{bold}. AUC = Area Under the Curve, Acc. = Accuracy, EER = Equal Error Rate.\n",
      "\\textbf{Expression Swap:} Comparison of different state-of-the-art detection approaches. The best results achieved for each public database are remarked in \\textbf{bold}. FF++ = FaceForensics++, AUC = Area Under the Curve, Acc. = Accuracy, EER = Equal Error Rate, TCR = True Classification Rate.\n",
      "Tables amount: 6\n",
      "\n",
      "\n",
      "2001.00181v2\n",
      "['csf-nSchur.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00182v1\n",
      "['veps_free.tex']\n",
      "Table of notations \\label{tab:notations}\n",
      "Bearer Establishment Time. 1 UE vs. 2 UEs \\label{tab:bearer_establishment}\n",
      "Error Type: AttributeError\n",
      "Error Message: 'NoneType' object has no attribute 'contents'\n",
      "\n",
      "\n",
      "2001.00183v4\n",
      "['qednewnew11.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 20817] \"eqnarray\" env expecting \\end{eqnarray}. Instead got \\end{thebibliography}\n",
      "\n",
      "\n",
      "\n",
      "2001.00184v1\n",
      "['paper.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00185v5\n",
      "['final.tex']\n",
      "Error Type: TypeError\n",
      "Error Message: [Line: 0, Offset 89692] Malformed argument. First and last elements must match a valid argument form\n",
      "\n",
      "\n",
      "2001.00186v1\n",
      "['commands.tex', 'main.tex']\n",
      "Error Type: TypeError\n",
      "Error Message: [Line: 0, Offset 1404] Malformed argument. First and last elements must match a valid argument forma\n",
      "\n",
      "\n",
      "2001.00187v1\n",
      "['AAAI-ChengY.2452.tex']\n",
      "Comparison between appearance-based methods.\n",
      "Ablation study.\n",
      "Additional analysis about different algorithms.\n",
      "Tables amount: 3\n",
      "\n",
      "\n",
      "2001.00188v3\n",
      "['Platonic_Quantum_final.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 5057] \"$\" env expecting $. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00190v2\n",
      "['iridate_four_arxiv.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 12962] \"eqnarray\" env expecting \\end{eqnarray}. Instead got \\end{document}\n",
      "\n",
      "\n",
      "\n",
      "2001.00191v1\n",
      "['template_ar.tex']\n",
      "UnicodeDecodeError occurred. File could not be loaded.\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00193v1\n",
      "['Perverse_Tilts_and_Dgstable_Combinatorics_v4.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 23825] \"$\" env expecting $. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00194v3\n",
      "['21cmMRS.tex']\n",
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 6975] \"$\" env expecting $. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00195v2\n",
      "['preamble.tex', 'preamble_clean.tex', 'web-api-clean.tex']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Type: EOFError\n",
      "Error Message: [Line: 0, Offset: 2746] \"it\" env expecting \\end{it}. Reached end of file.\n",
      "\n",
      "\n",
      "2001.00196v3\n",
      "['f4_repr.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00197v1\n",
      "['paper_add_v3.tex']\n",
      "Summary of the numerically motivated runs performed.  lmax is the maximum level of grid used,\n",
      "$lmax=14$ corresponds to about 1 AU of resolution, $lmax=13$ to 2 AU and $lmax=15$ to 0.5 AU. $n_{thres}$ is the density at which the sink particles are introduced while $n_{\\rm acc}$ is\n",
      "the density above which the gas is being accreted in the sink, $R_{sink}$ is the sink radius,\n",
      " $C_{\\rm acc}$ is the fraction of the gas mass above this density threshold and inside the sink radii which is \n",
      "accreted in a timestep. The parameter rest indicates whether the run uses an output of run $R2$ as starting point or is performed from $t=0$.\n",
      "Summary of the physically motivated runs performed.\n",
      "$\\mu$ is the mass to flux ratio normalised to the critical value,  $\\beta_{\\rm rot}$ is the ratio of rotation over gravitational energy, \n",
      "$\\theta$ is the initial angle between the magnetic field and the rotation axis, while ${\\mathcal M}$\n",
      "is the initial Mach number.\n",
      "Tables amount: 2\n",
      "\n",
      "\n",
      "2001.00202v3\n",
      "['SpLagK3_SYZ.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00203v1\n",
      "['ernest_henley_proton_shape.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00204v3\n",
      "['Paper.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00205v3\n",
      "['ms.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00207v1\n",
      "['Spectrum_AI_magazine_V7.tex']\n",
      "Tables amount: 0\n",
      "\n",
      "\n",
      "2001.00208v2\n",
      "['seg_pipo.tex']\n",
      "Comparison of features in U-Net and PIPO-FAN.\n",
      "\\label{tab:uni_val} Segmentation performance using different combinations of datasets (Dice \\%)\n",
      "\\label{tab:uni_net} Performance comparison with other networks on the BTCV dataset. \n",
      "\t(Dice \\%)\n",
      "\\label{tab:data_net_com2} Performance comparison with other networks on the combined all datasets. \n",
      "\t(Dice \\%)\n",
      "\\label{tab:2D_nets} Five-fold cross validation against other benchmark methods on two open challenge datasets. (Dice \\%)\n",
      "\\label{tab:val} Ablation study of PIPO-FAN network structures on LiTS dataset (Dice \\%)\n",
      "\\label{tab:test} Performance evaluation of varying the numbers of the input and output scales on LiTS dataset.\n",
      "\\label{tab:comparison} Comparison of segmentation accuracy (Dice \\%) on the LiTS test dataset. Results are taken from the challenge website (accessed on September 11, 2019).\n",
      "Tables amount: 8\n",
      "\n",
      "\n",
      "2001.00211v1\n",
      "['merge.tex', 'sublinear.tex']\n",
      "Error Type: AssertionError\n",
      "Error Message: Command \\item invalid in math mode.\n",
      "\n",
      "\n",
      "2001.00212v1\n",
      "['charmed_R1.tex']\n",
      "Tables amount: 0\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "source_directory = \"source_files/\"\n",
    "\n",
    "# TODO: Save paper name and authors as metadata\n",
    "error_counter = 0\n",
    "with open('tables.csv', 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=';', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    for paper in os.listdir(source_directory):\n",
    "        path = source_directory + paper\n",
    "        if os.path.isdir(path):\n",
    "            print(\"\\n\\n\" + paper)\n",
    "            tex_files = [x for x in os.listdir(path) if x.endswith('.tex')]\n",
    "            print(tex_files)\n",
    "\n",
    "            tex_content = []\n",
    "            for file in tex_files:\n",
    "                try:\n",
    "                    f = open(path + \"/\" + file, \"r\", encoding=\"utf8\")\n",
    "                    current_tex_content = f.read()\n",
    "                    tex_content.append(current_tex_content)\n",
    "                    f.close()\n",
    "                except UnicodeDecodeError as e:\n",
    "                    print(\"UnicodeDecodeError occurred. File could not be loaded.\")\n",
    "                    continue\n",
    "            #print(\"Complete tex source:\\n\" + complete_tex)\n",
    "\n",
    "            '''\n",
    "            Different LATEX tables:\n",
    "                -table\n",
    "                -table*\n",
    "                -tabular\n",
    "                -tabularx\n",
    "            '''\n",
    "            '''\n",
    "            found_tables = re.findall(r\"\\\\begin\\{table\\*?\\}.*?\\\\end\\{table\\*?\\}\", complete_tex, re.DOTALL)\n",
    "            for table in found_tables:\n",
    "                #r\"\\\\caption\\{(.*?)}\"\n",
    "                caption_match = re.search(r\"\\\\caption\\{(.*)}\", table)\n",
    "                if caption_match:\n",
    "                    found_caption = caption_match.group(1)\n",
    "                    original_caption = found_caption\n",
    "                    full_label_match = re.search(r\"\\\\label\\{.*?\\}\", found_caption)\n",
    "                    half_label_match = re.search(r\"\\\\label\\{.*\", found_caption)\n",
    "                    if full_label_match:\n",
    "                        found_caption = found_caption.replace(full_label_match.group(0), \"\")\n",
    "                        #print(\"Found full label: \" + full_label_match.group(0))\n",
    "                    elif half_label_match:\n",
    "                        found_caption = found_caption.replace(half_label_match.group(0), \"\")\n",
    "                        #print(\"Found half label: \" + half_label_match.group(0))\n",
    "                    print(\"Found caption: \" + found_caption)\n",
    "                    spamwriter.writerow([table.replace(\"\\n\", \" \"), found_caption, original_caption])\n",
    "                #print(\"Found table: \\n\" + table + \"\\n\\n\")\n",
    "            '''\n",
    "            \n",
    "            found_tables = []\n",
    "            title = \"\"\n",
    "            try:\n",
    "                for content in tex_content:\n",
    "                    soup = TexSoup(content)\n",
    "                    found_title = soup.title\n",
    "                    if found_title != None:\n",
    "                        title = ''.join(str(c) for c in found_title.contents)\n",
    "                    found_tables += list(soup.find_all(['table', 'table*']))\n",
    "                for table in found_tables:\n",
    "                    caption_content = ''.join(str(c) for c in table.caption.contents)\n",
    "                    print(caption_content)\n",
    "                    spamwriter.writerow([str(table).replace(\"\\n\", \" \"), caption_content, title])\n",
    "                print(\"Tables amount: \" + str(len(found_tables)))\n",
    "            except Exception as e:\n",
    "                error_counter += 1\n",
    "                print(f\"Error Type: {type(e).__name__}\")\n",
    "                error_message = str(e)[:100]\n",
    "                print(f\"Error Message: {error_message}\")\n",
    "\n",
    "        #break\n",
    "    print(error_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce419c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
