{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b5f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import shutil\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from lxml import etree\n",
    "from requests.exceptions import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bddc4650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed variables\n",
    "directory = \"source_files/\"\n",
    "metadata_file_path = directory + \"papers.csv\"\n",
    "\n",
    "relevant_publication_types = [\"JournalArticle\", \"Conference\", \"Review\"]\n",
    "MIN_CREATED_YEAR = 2023\n",
    "\n",
    "# Creating directory\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Creating metadata file\n",
    "if os.path.isfile(metadata_file_path) == False:\n",
    "    open(metadata_file_path, \"w\").close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0ea1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query_arxiv(spec, date):\n",
    "    \n",
    "    #Statistics\n",
    "    count_success = 0\n",
    "    count_failed = 0\n",
    "\n",
    "    # Request query\n",
    "    url = f'https://export.arxiv.org/oai2?verb=ListRecords&set={spec}&from={date}&until={date}&metadataPrefix=arXiv'\n",
    "    print(url)\n",
    "\n",
    "    # Request response\n",
    "    response = requests.get(url)\n",
    "    root = etree.fromstring(response.content)\n",
    "\n",
    "    #print(etree.tostring(root, pretty_print=True, encoding='unicode'))\n",
    "    \n",
    "    entry_ids = []\n",
    "    entry_titles = []\n",
    "    \n",
    "    namespaces = {\n",
    "        'oai': 'http://www.openarchives.org/OAI/2.0/',\n",
    "        'arxiv': 'http://arxiv.org/OAI/arXiv/'\n",
    "    }\n",
    "    record_list = root.findall('.//oai:ListRecords/oai:record', namespaces=namespaces)\n",
    "    print(\"\\nFound records:\",len(record_list))\n",
    "    record_counter = 0\n",
    "    for record in record_list:\n",
    "        record_counter += 1\n",
    "        if record_counter % 50 == 0:\n",
    "            print(str(record_counter) + \" records processed.\")\n",
    "        \n",
    "        try:\n",
    "            fid = record.find('.//arxiv:id', namespaces=namespaces).text\n",
    "            title = record.find('.//arxiv:title', namespaces=namespaces).text.replace(\"\\n\", \"\").replace(\"  \", \" \")\n",
    "            license = record.find('.//arxiv:license', namespaces=namespaces).text\n",
    "            created = record.find('.//arxiv:created', namespaces=namespaces).text\n",
    "            #print(fid.text, title.text.replace(\"\\n\", \"\").replace(\"  \", \" \"), license.text, created.text)\n",
    "\n",
    "            year_match = re.match(\"(\\d\\d\\d\\d)-\\d\\d\\-\\d\\d\", created)\n",
    "            if year_match:\n",
    "                if int(year_match.group(1)) >= MIN_CREATED_YEAR:\n",
    "                    if (license == \"http://creativecommons.org/licenses/by/4.0/\" or\n",
    "                    license == \"http://creativecommons.org/licenses/by-sa/4.0/\" or\n",
    "                    license == \"http://creativecommons.org/licenses/by-nc-sa/4.0/\" or\n",
    "                    license == \"http://creativecommons.org/licenses/by-nc-nd/4.0/\" or\n",
    "                    license == \"http://creativecommons.org/publicdomain/zero/1.0/\"):\n",
    "                        if check_new_paper(fid):\n",
    "                            entry_ids.append(fid)\n",
    "                            entry_titles.append(title)\n",
    "                        #print(\"Success!\")\n",
    "                    elif (license != \"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\"):\n",
    "                        print(\"Bad license:\", license.text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error Type: {type(e).__name__}\")\n",
    "            error_message = str(e)[:100]\n",
    "            print(f\"Error Message: {error_message}\")\n",
    "\n",
    "    print(\"\\nNumber of entries:\", len(entry_ids))\n",
    "    \n",
    "    # Downloading the papers\n",
    "    for i in range(len(entry_ids)):\n",
    "        time.sleep(3)\n",
    "        if download_source_paper(entry_ids[i], entry_titles[i], spec):\n",
    "            print(f\"{i+1}. Paper: {entry_ids[i]} was successfully downloaded and extracted.\")\n",
    "            count_success += 1\n",
    "        else:\n",
    "            print(f\"{i+1}. Paper: {entry_ids[i]} was not downloaded/extracted.\")\n",
    "            count_failed += 1\n",
    "        #break\n",
    "    \n",
    "    print(\"\\nStatistics:\")\n",
    "    print(f\"Successfully downloaded papers: {count_success}\")\n",
    "    print(f\"Failed downloaded papers: {count_failed}\")\n",
    "    \n",
    "# Download the found ids and extract tar.gz archive\n",
    "def download_source_paper(entry_id, entry_title, spec):       \n",
    "    # Downloading\n",
    "    source_link = \"https://arxiv.org/src/\" + entry_id\n",
    "\n",
    "    response = requests.get(source_link)\n",
    "    #print(response.content)\n",
    "    content_disposition = response.headers.get('content-disposition', '')\n",
    "    filename_match = re.search(r'filename=\"(.+)\"', content_disposition)\n",
    "    if filename_match:\n",
    "        filename = filename_match.group(1)\n",
    "        if re.fullmatch(r\".*\\.tar.gz\", filename) == False:\n",
    "            print(f\"File is of unexpected data format. ({filename})\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"File name was not found. ({entry_id})\")\n",
    "        return False\n",
    "    filepath = directory + filename\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Extracting\n",
    "    try:\n",
    "        extracting_path = directory + entry_id.replace('/', '-')\n",
    "        t = tarfile.open(filepath)\n",
    "        t.extractall(path = extracting_path)\n",
    "        t.close()\n",
    "\n",
    "        # Saving meta information\n",
    "        with open(metadata_file_path, \"a\", encoding=\"utf-8\") as meta_file:\n",
    "            meta_file.write(entry_id + \";\" + entry_title + \";\" + spec + \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error for \" + filename + \": \" + str(e).split(\"\\n\")[0])\n",
    "        try:\n",
    "            if os.path.isdir(extracting_path):\n",
    "                shutil.rmtree(extracting_path) # Removing the paper\n",
    "            os.remove(filepath)\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "    # Deleting downloaded archive/file\n",
    "    os.remove(filepath)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Check whether the paper is new or already downloaded\n",
    "def check_new_paper(entry_id):\n",
    "    with open (metadata_file_path, \"r\") as metadata_file:\n",
    "        spamreader = csv.reader(metadata_file, delimiter=';', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            if row[0] == entry_id:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ef682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select spec and date\n",
    "spec = \"cs\"\n",
    "date = \"2024-09-27\"\n",
    "\n",
    "# Download papers from a specific date\n",
    "query_arxiv(spec, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf955522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select spec, month and year\n",
    "spec = \"cs\"\n",
    "month = \"05\"\n",
    "year = \"2024\"\n",
    "\n",
    "# Download papers from a specific month\n",
    "for day in range(1, 31):\n",
    "    time.sleep(6)\n",
    "    if day < 10:\n",
    "        query_arxiv(spec, f\"{year}-{month}-0{day}\")\n",
    "    else:\n",
    "        query_arxiv(spec, f\"{year}-{month}-{day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ef1c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11880"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_ids = []\n",
    "paper_titles = []\n",
    "\n",
    "with open(directory + \"papers_processed.csv\") as metadata_file:\n",
    "    csv_reader = csv.reader(metadata_file, delimiter=';', quotechar='|')\n",
    "    for row in csv_reader:\n",
    "        paper_ids.append(row[0])\n",
    "        paper_titles.append(row[0])\n",
    "        \n",
    "len(paper_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 5#len(paper_ids)\n",
    "\n",
    "for i in range(start_index, end_index):\n",
    "    print(i)\n",
    "    download_source_paper(paper_ids[i], paper_titles[i], \"cs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21b399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
